{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import Column, Integer, Float, String, DateTime, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.dialects.mysql import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"\"\n",
    "MODE = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.environ.get('DB_USER')\n",
    "password = os.environ.get('DB_PASS')\n",
    "host = os.environ.get('DB_HOST')\n",
    "port = os.environ.get('DB_PORT')\n",
    "database = os.environ.get('DB_NAME')\n",
    "url = f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "engine = create_engine(url)\n",
    "\n",
    "query_races = 'SELECT * FROM races'\n",
    "query_race_results = 'SELECT * FROM race_results'\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    race_df = pd.read_sql_query(sql=text(query_races), con=connection)\n",
    "    race_results_df = pd.read_sql_query(sql=text(query_race_results), con=connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_state_features(df):\n",
    "    return_df = df.copy()\n",
    "    return_df[\"race_course\"] = df[\"race_state\"].str[1]\n",
    "    return_df[\"race_distance\"] = df[\"race_state\"].str[2:6]\n",
    "    return_df[\"race_weather\"] = df[\"race_state\"].str[15]\n",
    "    return_df[\"race_state\"] = df[\"race_state\"].str[23]\n",
    "    return_df[\"race_start\"] =  df[\"race_state\"].str[32:37].str.replace(\":\", \"\")\n",
    "    return return_df\n",
    "\n",
    "def get_sex_and_age(df):\n",
    "    return_df = df.copy()\n",
    "    return_df[\"sex\"] = return_df[\"sex_and_age\"].str[0]\n",
    "    return_df[\"age\"] = return_df[\"sex_and_age\"].str[1]\n",
    "    return return_df\n",
    "\n",
    "def get_horse_weight(df):\n",
    "    return_df = df.copy()\n",
    "    return_df[\"difference_weight\"] = return_df[\"horse_weight\"].str[3:]\n",
    "    return_df[\"difference_weight\"] = return_df[\"difference_weight\"].replace(re.compile(\"\\(|\\)\"), \"\", regex=True)\n",
    "    return_df[return_df['difference_weight'] == ''] = -9999\n",
    "    return_df[\"difference_weight\"] = return_df[\"difference_weight\"].astype(int)\n",
    "    return_df[return_df['difference_weight'] == -9999] = None\n",
    "    return_df[\"horse_weight\"] = return_df[\"horse_weight\"].str[0:3]\n",
    "    return return_df\n",
    "\n",
    "def get_date(df, mode):\n",
    "    return_df = df.copy()\n",
    "    return_df['date'] = return_df['date'].str.split(' ', expand=True)[0]\n",
    "    if mode == \"train\":\n",
    "        return_df['date'] = pd.to_datetime(return_df['date'], format='%Y年%m月%d日')\n",
    "        return_df['day_of_year'] = return_df['date'].dt.day_of_year\n",
    "    elif mode == \"predict\":\n",
    "        return_df['date'] = pd.to_datetime(return_df['date'].str[:-3], format='%m月%d日')\n",
    "        return_df['day_of_year'] = 2024\n",
    "    return_df['date_cos'] = np.cos(2 * np.pi * return_df['day_of_year'] / return_df['day_of_year'].max())\n",
    "    return_df['date_sin'] = np.sin(2 * np.pi * return_df['day_of_year'] / return_df['day_of_year'].max())\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(race_df, race_results_df, mode):\n",
    "    USE_COLUMNS = [\n",
    "        \"id\", \"race_name\", \"race_place\", \"number_of_entries\", \"race_state\", \"date\",\n",
    "        \"box\", \"horse_order\", \"sex_and_age\", \"burden_weight\",\n",
    "        \"jockey\", \"horse_weight\", \"horse_trainer\", \"horse_owner\"\n",
    "    ]\n",
    "\n",
    "    if mode == \"train\":\n",
    "        merge_df = pd.merge(race_df, race_results_df, on='id', how='left').dropna(subset=[\"id\"])\n",
    "        USE_COLUMNS.append(\"rank\")\n",
    "        use_df = merge_df[USE_COLUMNS]\n",
    "    elif mode == \"predict\":\n",
    "        merge_df = pd.merge(race_df, race_results_df, left_on='id', right_on='race_id', how='left').dropna(subset=[\"id\"])\n",
    "        use_df = merge_df[USE_COLUMNS]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported mode. Use 'train' or 'predict'.\")\n",
    "\n",
    "    df = use_df.copy()\n",
    "    df = get_race_state_features(df)\n",
    "    df = get_sex_and_age(df)\n",
    "    df = get_horse_weight(df)\n",
    "    df = get_date(df, mode)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df, cols, mode, output_path):\n",
    "    return_df = df.copy()\n",
    "    return_df[cols] = return_df[cols].fillna('missing')\n",
    "\n",
    "    oe = preprocessing.OrdinalEncoder(\n",
    "        handle_unknown=\"use_encoded_value\",\n",
    "        unknown_value=-1,\n",
    "    )\n",
    "\n",
    "    categories_filename = os.path.join(output_path, \"categories.joblib\")\n",
    "\n",
    "    if mode == \"train\":\n",
    "        return_df[cols] = oe.fit_transform(return_df[cols])\n",
    "        dump(oe, categories_filename)\n",
    "    elif mode == \"predict\":\n",
    "        loaded_encoder = load(categories_filename)\n",
    "        return_df[cols] = loaded_encoder.transform(return_df[cols])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported mode. Use 'train' or 'predict'.\")\n",
    "    return_df = return_df.replace({'nan': np.nan})\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, int_columns, float_columns, mode):\n",
    "    return_df = df.copy()\n",
    "    if mode == \"train\":\n",
    "        return_df['rank'] = return_df['rank'].replace({'1': 1, '2': 1, '3': 1})\n",
    "        return_df.loc[~(return_df['rank'] == 1), 'rank'] = 0\n",
    "\n",
    "    for col in int_columns:\n",
    "        return_df[col] = pd.to_numeric(return_df[col], errors='coerce').fillna(0).astype(int)\n",
    "    for col in float_columns:\n",
    "        return_df[col] = pd.to_numeric(return_df[col], errors='coerce')\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, mode, output_path):\n",
    "    ENCODING_COLUMNS = [\n",
    "        \"race_name\", \"race_place\",\n",
    "        \"race_state\", \"race_course\", \"race_weather\",\n",
    "        \"sex_and_age\", \"sex\",\n",
    "        \"jockey\", \"horse_trainer\", \"horse_owner\"\n",
    "    ]\n",
    "    \n",
    "    INT_COLUMNS = [\n",
    "        \"id\", \"box\", \"horse_order\", \"horse_weight\", \"race_distance\",\n",
    "        \"race_start\", \"age\", \"day_of_year\", \"number_of_entries\",\n",
    "        \"difference_weight\", \"day_of_year\"\n",
    "    ]\n",
    "    if mode == \"train\":\n",
    "        INT_COLUMNS.append(\"rank\")\n",
    "    \n",
    "    FLOAT_COLUMNS =[\n",
    "        \"burden_weight\"\n",
    "    ]\n",
    "    \n",
    "    encoded_df = label_encoder(df, ENCODING_COLUMNS, mode, output_path)\n",
    "    \n",
    "    cleaned_df = clean_df(encoded_df, INT_COLUMNS, FLOAT_COLUMNS, mode)\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\katsuyaSuzuki\\Desktop\\dev\\KeibaAI\\ML\\myvenv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:189: RuntimeWarning: invalid value encountered in cast\n",
      "  return values.astype(dtype, copy=copy)\n"
     ]
    }
   ],
   "source": [
    "feature_engineered_df = get_all_features(race_df, race_results_df, MODE)\n",
    "preprocessed_df = preprocess_data(feature_engineered_df, MODE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    return_df = df.copy()\n",
    "    train_df = return_df[return_df['date'] < dt.datetime(2021, 1,1)].drop('date', axis=1)\n",
    "    val_df = return_df[(return_df['date'] >= dt.datetime(2021, 1,1)) & (return_df['date'] < dt.datetime(2022, 1,1))].drop('date', axis=1)\n",
    "    test_df = return_df[return_df['date'] > dt.datetime(2022, 1, 1)].drop('date', axis=1)\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_df(preprocessed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_target(df):\n",
    "    return_df = df.copy()\n",
    "    X = return_df.drop('rank', axis=1)\n",
    "    y = return_df['rank']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_target(train_df)\n",
    "X_val, y_val = split_target(val_df)\n",
    "X_test, y_test = split_target(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.705259\tvalid_1's auc: 0.680797\n",
      "[20]\ttraining's auc: 0.725142\tvalid_1's auc: 0.692725\n",
      "[30]\ttraining's auc: 0.738792\tvalid_1's auc: 0.695706\n",
      "[40]\ttraining's auc: 0.751569\tvalid_1's auc: 0.698783\n",
      "[50]\ttraining's auc: 0.762158\tvalid_1's auc: 0.700493\n",
      "[60]\ttraining's auc: 0.771826\tvalid_1's auc: 0.701559\n",
      "[70]\ttraining's auc: 0.780692\tvalid_1's auc: 0.702267\n",
      "[80]\ttraining's auc: 0.78893\tvalid_1's auc: 0.702533\n",
      "[90]\ttraining's auc: 0.795841\tvalid_1's auc: 0.702762\n",
      "[100]\ttraining's auc: 0.802809\tvalid_1's auc: 0.701953\n",
      "[110]\ttraining's auc: 0.809491\tvalid_1's auc: 0.702234\n",
      "[120]\ttraining's auc: 0.815698\tvalid_1's auc: 0.70201\n",
      "[130]\ttraining's auc: 0.821881\tvalid_1's auc: 0.702241\n",
      "[140]\ttraining's auc: 0.827382\tvalid_1's auc: 0.702115\n",
      "[150]\ttraining's auc: 0.83277\tvalid_1's auc: 0.701186\n",
      "[160]\ttraining's auc: 0.837546\tvalid_1's auc: 0.701324\n",
      "[170]\ttraining's auc: 0.843091\tvalid_1's auc: 0.701304\n",
      "[180]\ttraining's auc: 0.848163\tvalid_1's auc: 0.701163\n",
      "[190]\ttraining's auc: 0.853103\tvalid_1's auc: 0.700886\n",
      "[200]\ttraining's auc: 0.857493\tvalid_1's auc: 0.701181\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's auc: 0.80755\tvalid_1's auc: 0.702771\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, n_estimators=10000, objective=&#x27;binary&#x27;,\n",
       "               random_state=74)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, n_estimators=10000, objective=&#x27;binary&#x27;,\n",
       "               random_state=74)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='auc', n_estimators=10000, objective='binary',\n",
       "               random_state=74)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = lgbm.Dataset(X_train, y_train)\n",
    "val_set = lgbm.Dataset(X_val, y_val)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 10000,\n",
    "    'random_state': 74,\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True), lgbm.log_evaluation(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filename = os.path.join(OUTPUT_PATH, \"model.joblib\")\n",
    "dump(clf, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model, X_test, y_test, version, output_dir):\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_binary = model.predict(X_test)\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC Score: {auc_score}')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_binary)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    cm_filename = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_filename)\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    rc_filename = os.path.join(output_dir, \"roc_curve.png\")\n",
    "    plt.savefig(rc_filename)\n",
    "    plt.close()\n",
    "\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                        index = X_test.columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances)\n",
    "\n",
    "    lgbm.plot_importance(model, importance_type='split', max_num_features=10)\n",
    "    plt.title('Feature Importance')\n",
    "    fi_filename = os.path.join(output_dir, \"feature_importance.png\")\n",
    "    plt.savefig(fi_filename)\n",
    "    plt.close()\n",
    "\n",
    "    evaluation_results = {\n",
    "        'importances': feature_importances, \n",
    "        'AUC': auc_score,\n",
    "        'TP': int(cm[1][1]),\n",
    "        'FP': int(cm[0][1]),\n",
    "        'FN': int(cm[1][0]),\n",
    "        'TN': int(cm[0][0]),\n",
    "        'FPR': fpr, \n",
    "        'TPR': tpr,\n",
    "        'memo': 'memo',\n",
    "        'version': version,\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katsuyaSuzuki\\AppData\\Local\\Temp\\ipykernel_37800\\2695455613.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ModelEvaluation(Base):\n",
    "    __tablename__ = 'model_evaluation'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    feature_importance_json = Column(JSON)\n",
    "    TP = Column(Integer)\n",
    "    FP = Column(Integer)\n",
    "    FN = Column(Integer)\n",
    "    TN = Column(Integer)\n",
    "    FPR = Column(JSON)\n",
    "    TPR = Column(JSON)\n",
    "    AUC = Column(Float)\n",
    "    memo = Column(Text)\n",
    "    version = Column(String(255))\n",
    "    created_date = Column(DateTime, default=dt.datetime.utcnow)\n",
    "\n",
    "def save_evaluation(evaluation_results, engine):\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    new_evaluation = ModelEvaluation(\n",
    "        feature_importance_json=evaluation_results[\"importances\"].to_json(),\n",
    "        TP=evaluation_results[\"TP\"],\n",
    "        FP=evaluation_results[\"FP\"],\n",
    "        FN=evaluation_results[\"FN\"],\n",
    "        TN=evaluation_results[\"TN\"],\n",
    "        FPR=json.dumps(evaluation_results[\"FPR\"].tolist()),\n",
    "        TPR=json.dumps(evaluation_results[\"TPR\"].tolist()),\n",
    "        AUC=evaluation_results[\"AUC\"],\n",
    "        memo=evaluation_results[\"memo\"],\n",
    "        version=evaluation_results[\"version\"],\n",
    "        created_date=dt.datetime.utcnow()\n",
    "    )\n",
    "    \n",
    "    session.add(new_evaluation)\n",
    "    session.commit()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC Score: 0.6964802350642254\n",
      "                   importance\n",
      "jockey                    580\n",
      "horse_owner               392\n",
      "horse_trainer             373\n",
      "horse_weight              326\n",
      "race_name                 191\n",
      "day_of_year               158\n",
      "date_cos                  145\n",
      "date_sin                  145\n",
      "age                       126\n",
      "number_of_entries         124\n",
      "race_start                121\n",
      "difference_weight         118\n",
      "sex_and_age                97\n",
      "horse_order                80\n",
      "burden_weight              79\n",
      "box                        50\n",
      "race_place                 44\n",
      "race_distance              25\n",
      "race_state                 15\n",
      "race_weather               11\n",
      "race_course                 9\n",
      "sex                         1\n",
      "id                          0\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = evaluate_model_performance(clf, X_test, y_test, \"v0.0\", OUTPUT_PATH)\n",
    "save_evaluation(evaluation_results, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測フロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開催予定レースデータ取得(RDSから)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_data():\n",
    "    query_weekly_races = 'SELECT * FROM weekly_races'\n",
    "    query_race_entries = 'SELECT * FROM race_entries'\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        weekly_races_df = pd.read_sql_query(sql=text(query_weekly_races), con=connection)\n",
    "        race_entries_df = pd.read_sql_query(sql=text(query_race_entries), con=connection)\n",
    "\n",
    "    return weekly_races_df, race_entries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_races_df, race_entries_df = load_new_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\katsuyaSuzuki\\Desktop\\dev\\KeibaAI\\ML\\myvenv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:189: RuntimeWarning: invalid value encountered in cast\n",
      "  return values.astype(dtype, copy=copy)\n"
     ]
    }
   ],
   "source": [
    "feature_engineered_df = get_all_features(weekly_races_df, race_entries_df, MODE)\n",
    "preprocessed_df = preprocess_data(feature_engineered_df, MODE, OUTPUT_PATH).drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデル取得(S3から)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(output_path):\n",
    "    model_path = os.path.join(output_path, \"model.joblib\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    model = load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(preprocessed_df)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測結果保存(RDSに)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predict_proba_column(engine, table_name='race_entries', column_name='predict_proba'):\n",
    "    Base.metadata.reflect(engine)\n",
    "    table = Base.metadata.tables[table_name]\n",
    "    \n",
    "    if column_name not in table.c:\n",
    "        with engine.connect() as conn:\n",
    "            sql_statement = text(f'ALTER TABLE {table_name} ADD COLUMN {column_name} FLOAT')\n",
    "            conn.execute(sql_statement)\n",
    "            print(f\"Added '{column_name}' column to '{table_name}' table.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' already exists in '{table_name}' table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(race_entries_df, predictions, table_name='race_entries', column_name='predict_proba'):\n",
    "    add_predict_proba_column(engine, table_name, column_name)\n",
    "\n",
    "    race_entries_df[column_name] = predictions\n",
    "\n",
    "    race_entries_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Saved predictions to '{table_name}' table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'predict_proba' column to 'race_entries' table.\n",
      "Saved predictions to 'race_entries' table.\n"
     ]
    }
   ],
   "source": [
    "save_predictions(race_entries_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff69bacaadc7e2cd0d1da4a544b42c7a912005d437346d3412f68a334aa5606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
