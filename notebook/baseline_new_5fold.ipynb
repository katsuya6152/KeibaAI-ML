{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import Column, Integer, Float, String, DateTime, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.dialects.mysql import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"output\"\n",
    "MODE = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.environ.get('DB_USER')\n",
    "password = os.environ.get('DB_PASS')\n",
    "host = os.environ.get('DB_HOST')\n",
    "port = os.environ.get('DB_PORT')\n",
    "database = os.environ.get('DB_NAME')\n",
    "url = f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "engine = create_engine(url)\n",
    "\n",
    "query_races = 'SELECT * FROM races'\n",
    "query_race_results = 'SELECT * FROM race_results'\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    race_df = pd.read_sql_query(sql=text(query_races), con=connection)\n",
    "    race_results_df = pd.read_sql_query(sql=text(query_race_results), con=connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_state_features(df):\n",
    "    return_df = df.copy()\n",
    "    return_df[\"race_course\"] = df[\"race_state\"].str[1]\n",
    "    return_df[\"race_distance\"] = df[\"race_state\"].str[2:6]\n",
    "    return_df[\"race_weather\"] = df[\"race_state\"].str[15]\n",
    "    return_df[\"race_state\"] = df[\"race_state\"].str[23]\n",
    "    return_df[\"race_start\"] =  df[\"race_state\"].str[32:37].str.replace(\":\", \"\")\n",
    "    return return_df\n",
    "\n",
    "def get_sex_and_age(df):\n",
    "    return_df = df.copy()\n",
    "    return_df[\"sex\"] = return_df[\"sex_and_age\"].str[0]\n",
    "    return_df[\"age\"] = return_df[\"sex_and_age\"].str[1]\n",
    "    return return_df\n",
    "\n",
    "def get_horse_weight(df):\n",
    "    return_df = df.copy()\n",
    "    return_df[\"difference_weight\"] = return_df[\"horse_weight\"].str[3:]\n",
    "    return_df[\"difference_weight\"] = return_df[\"difference_weight\"].replace(re.compile(\"\\(|\\)\"), \"\", regex=True)\n",
    "    return_df[return_df['difference_weight'] == ''] = -9999\n",
    "    return_df[\"difference_weight\"] = return_df[\"difference_weight\"].astype(int)\n",
    "    return_df[return_df['difference_weight'] == -9999] = None\n",
    "    return_df[\"horse_weight\"] = return_df[\"horse_weight\"].str[0:3]\n",
    "    return return_df\n",
    "\n",
    "def get_date(df, mode):\n",
    "    return_df = df.copy()\n",
    "    return_df['date'] = return_df['date'].str.split(' ', expand=True)[0]\n",
    "    if mode == \"train\":\n",
    "        return_df['date'] = pd.to_datetime(return_df['date'], format='%Y年%m月%d日')\n",
    "        return_df['day_of_year'] = return_df['date'].dt.day_of_year\n",
    "    elif mode == \"predict\":\n",
    "        return_df['date'] = pd.to_datetime(return_df['date'].str[:-3], format='%m月%d日')\n",
    "        return_df['day_of_year'] = 2024\n",
    "    return_df['date_cos'] = np.cos(2 * np.pi * return_df['day_of_year'] / return_df['day_of_year'].max())\n",
    "    return_df['date_sin'] = np.sin(2 * np.pi * return_df['day_of_year'] / return_df['day_of_year'].max())\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(race_df, race_results_df, mode):\n",
    "    USE_COLUMNS = [\n",
    "        \"id\", \"race_name\", \"race_place\", \"number_of_entries\", \"race_state\", \"date\",\n",
    "        \"box\", \"horse_order\", \"sex_and_age\", \"burden_weight\",\n",
    "        \"jockey\", \"horse_weight\", \"horse_trainer\", \"horse_owner\"\n",
    "    ]\n",
    "\n",
    "    if mode == \"train\":\n",
    "        merge_df = pd.merge(race_df, race_results_df, on='id', how='left').dropna(subset=[\"id\"])\n",
    "        USE_COLUMNS.append(\"rank\")\n",
    "        use_df = merge_df[USE_COLUMNS]\n",
    "    elif mode == \"predict\":\n",
    "        merge_df = pd.merge(race_df, race_results_df, left_on='id', right_on='race_id', how='left').dropna(subset=[\"id\"])\n",
    "        use_df = merge_df[USE_COLUMNS]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported mode. Use 'train' or 'predict'.\")\n",
    "\n",
    "    df = use_df.copy()\n",
    "    df = get_race_state_features(df)\n",
    "    df = get_sex_and_age(df)\n",
    "    df = get_horse_weight(df)\n",
    "    df = get_date(df, mode)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df, cols, mode, output_path):\n",
    "    return_df = df.copy()\n",
    "    return_df[cols] = return_df[cols].fillna('missing')\n",
    "\n",
    "    oe = preprocessing.OrdinalEncoder(\n",
    "        handle_unknown=\"use_encoded_value\",\n",
    "        unknown_value=-1,\n",
    "    )\n",
    "\n",
    "    categories_filename = os.path.join(output_path, \"categories.joblib\")\n",
    "\n",
    "    if mode == \"train\":\n",
    "        return_df[cols] = oe.fit_transform(return_df[cols])\n",
    "        dump(oe, categories_filename)\n",
    "    elif mode == \"predict\":\n",
    "        loaded_encoder = load(categories_filename)\n",
    "        return_df[cols] = loaded_encoder.transform(return_df[cols])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported mode. Use 'train' or 'predict'.\")\n",
    "    return_df = return_df.replace({'nan': np.nan})\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, int_columns, float_columns, mode):\n",
    "    return_df = df.copy()\n",
    "    if mode == \"train\":\n",
    "        return_df['rank'] = return_df['rank'].replace({'1': 1, '2': 1, '3': 1})\n",
    "        return_df.loc[~(return_df['rank'] == 1), 'rank'] = 0\n",
    "\n",
    "    for col in int_columns:\n",
    "        return_df[col] = pd.to_numeric(return_df[col], errors='coerce').fillna(0).astype('int64')\n",
    "    for col in float_columns:\n",
    "        return_df[col] = pd.to_numeric(return_df[col], errors='coerce')\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, mode, output_path):\n",
    "    ENCODING_COLUMNS = [\n",
    "        \"race_name\", \"race_place\",\n",
    "        \"race_state\", \"race_course\", \"race_weather\",\n",
    "        \"sex_and_age\", \"sex\",\n",
    "        \"jockey\", \"horse_trainer\", \"horse_owner\"\n",
    "    ]\n",
    "    \n",
    "    INT_COLUMNS = [\n",
    "        \"id\", \"box\", \"horse_order\", \"horse_weight\", \"race_distance\",\n",
    "        \"race_start\", \"age\", \"day_of_year\", \"number_of_entries\",\n",
    "        \"difference_weight\", \"day_of_year\"\n",
    "    ]\n",
    "    if mode == \"train\":\n",
    "        INT_COLUMNS.append(\"rank\")\n",
    "    \n",
    "    FLOAT_COLUMNS =[\n",
    "        \"burden_weight\"\n",
    "    ]\n",
    "    \n",
    "    encoded_df = label_encoder(df, ENCODING_COLUMNS, mode, output_path)\n",
    "    \n",
    "    cleaned_df = clean_df(encoded_df, INT_COLUMNS, FLOAT_COLUMNS, mode)\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineered_df = get_all_features(race_df, race_results_df, MODE)\n",
    "preprocessed_df = preprocess_data(feature_engineered_df, MODE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model, X_test, y_test, version, output_dir):\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_binary = model.predict(X_test)\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC Score: {auc_score}')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_binary)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    cm_filename = os.path.join(output_dir, f\"{version}_confusion_matrix.png\")\n",
    "    plt.savefig(cm_filename)\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    rc_filename = os.path.join(output_dir, f\"{version}_roc_curve.png\")\n",
    "    plt.savefig(rc_filename)\n",
    "    plt.close()\n",
    "\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                        index = X_test.columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances)\n",
    "\n",
    "    lgbm.plot_importance(model, importance_type='split', max_num_features=10)\n",
    "    plt.title('Feature Importance')\n",
    "    fi_filename = os.path.join(output_dir, f\"{version}_feature_importance.png\")\n",
    "    plt.savefig(fi_filename)\n",
    "    plt.close()\n",
    "\n",
    "    evaluation_results = {\n",
    "        'importances': feature_importances, \n",
    "        'AUC': auc_score,\n",
    "        'TP': int(cm[1][1]),\n",
    "        'FP': int(cm[0][1]),\n",
    "        'FN': int(cm[1][0]),\n",
    "        'TN': int(cm[0][0]),\n",
    "        'FPR': fpr, \n",
    "        'TPR': tpr,\n",
    "        'memo': 'memo',\n",
    "        'version': version,\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katsuyaSuzuki\\AppData\\Local\\Temp\\ipykernel_14668\\2695455613.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ModelEvaluation(Base):\n",
    "    __tablename__ = 'model_evaluation'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    feature_importance_json = Column(JSON)\n",
    "    TP = Column(Integer)\n",
    "    FP = Column(Integer)\n",
    "    FN = Column(Integer)\n",
    "    TN = Column(Integer)\n",
    "    FPR = Column(JSON)\n",
    "    TPR = Column(JSON)\n",
    "    AUC = Column(Float)\n",
    "    memo = Column(Text)\n",
    "    version = Column(String(255))\n",
    "    created_date = Column(DateTime, default=dt.datetime.utcnow)\n",
    "\n",
    "def save_evaluation(evaluation_results, engine):\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    new_evaluation = ModelEvaluation(\n",
    "        feature_importance_json=evaluation_results[\"importances\"].to_json(),\n",
    "        TP=evaluation_results[\"TP\"],\n",
    "        FP=evaluation_results[\"FP\"],\n",
    "        FN=evaluation_results[\"FN\"],\n",
    "        TN=evaluation_results[\"TN\"],\n",
    "        FPR=json.dumps(evaluation_results[\"FPR\"].tolist()),\n",
    "        TPR=json.dumps(evaluation_results[\"TPR\"].tolist()),\n",
    "        AUC=evaluation_results[\"AUC\"],\n",
    "        memo=evaluation_results[\"memo\"],\n",
    "        version=evaluation_results[\"version\"],\n",
    "        created_date=dt.datetime.utcnow()\n",
    "    )\n",
    "    \n",
    "    session.add(new_evaluation)\n",
    "    session.commit()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0---------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.725888\tvalid_1's auc: 0.668764\n",
      "[20]\ttraining's auc: 0.75588\tvalid_1's auc: 0.682515\n",
      "[30]\ttraining's auc: 0.776103\tvalid_1's auc: 0.688889\n",
      "[40]\ttraining's auc: 0.793976\tvalid_1's auc: 0.690527\n",
      "[50]\ttraining's auc: 0.808807\tvalid_1's auc: 0.692421\n",
      "[60]\ttraining's auc: 0.82016\tvalid_1's auc: 0.69265\n",
      "[70]\ttraining's auc: 0.831724\tvalid_1's auc: 0.69288\n",
      "[80]\ttraining's auc: 0.842345\tvalid_1's auc: 0.689974\n",
      "[90]\ttraining's auc: 0.852332\tvalid_1's auc: 0.688711\n",
      "[100]\ttraining's auc: 0.86037\tvalid_1's auc: 0.687754\n",
      "[110]\ttraining's auc: 0.868594\tvalid_1's auc: 0.68368\n",
      "[120]\ttraining's auc: 0.875331\tvalid_1's auc: 0.680024\n",
      "[130]\ttraining's auc: 0.883289\tvalid_1's auc: 0.677443\n",
      "[140]\ttraining's auc: 0.88939\tvalid_1's auc: 0.675278\n",
      "[150]\ttraining's auc: 0.896548\tvalid_1's auc: 0.674036\n",
      "[160]\ttraining's auc: 0.902354\tvalid_1's auc: 0.674389\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.830512\tvalid_1's auc: 0.69322\n",
      "Test AUC Score: 0.6863655721280231\n",
      "                   importance\n",
      "jockey                    327\n",
      "horse_trainer             264\n",
      "horse_owner               247\n",
      "horse_weight              174\n",
      "id                        105\n",
      "race_name                  93\n",
      "day_of_year                90\n",
      "horse_order                86\n",
      "date_sin                   83\n",
      "race_start                 79\n",
      "difference_weight          77\n",
      "number_of_entries          74\n",
      "age                        70\n",
      "sex_and_age                67\n",
      "date_cos                   64\n",
      "burden_weight              62\n",
      "box                        43\n",
      "race_distance              27\n",
      "race_place                 26\n",
      "race_course                 6\n",
      "race_weather                4\n",
      "sex                         1\n",
      "race_state                  1\n",
      "fold_1---------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.708399\tvalid_1's auc: 0.673696\n",
      "[20]\ttraining's auc: 0.732651\tvalid_1's auc: 0.68595\n",
      "[30]\ttraining's auc: 0.751258\tvalid_1's auc: 0.692855\n",
      "[40]\ttraining's auc: 0.766744\tvalid_1's auc: 0.700454\n",
      "[50]\ttraining's auc: 0.779171\tvalid_1's auc: 0.69997\n",
      "[60]\ttraining's auc: 0.789886\tvalid_1's auc: 0.701592\n",
      "[70]\ttraining's auc: 0.797967\tvalid_1's auc: 0.702539\n",
      "[80]\ttraining's auc: 0.80823\tvalid_1's auc: 0.702719\n",
      "[90]\ttraining's auc: 0.817171\tvalid_1's auc: 0.703178\n",
      "[100]\ttraining's auc: 0.825022\tvalid_1's auc: 0.702765\n",
      "[110]\ttraining's auc: 0.831968\tvalid_1's auc: 0.703147\n",
      "[120]\ttraining's auc: 0.839887\tvalid_1's auc: 0.70198\n",
      "[130]\ttraining's auc: 0.846348\tvalid_1's auc: 0.702402\n",
      "[140]\ttraining's auc: 0.852018\tvalid_1's auc: 0.703372\n",
      "[150]\ttraining's auc: 0.857716\tvalid_1's auc: 0.702727\n",
      "[160]\ttraining's auc: 0.863354\tvalid_1's auc: 0.701752\n",
      "[170]\ttraining's auc: 0.869187\tvalid_1's auc: 0.700853\n",
      "[180]\ttraining's auc: 0.874569\tvalid_1's auc: 0.700754\n",
      "[190]\ttraining's auc: 0.87923\tvalid_1's auc: 0.699633\n",
      "[200]\ttraining's auc: 0.884552\tvalid_1's auc: 0.69922\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's auc: 0.829278\tvalid_1's auc: 0.703751\n",
      "Test AUC Score: 0.6915747800089297\n",
      "                   importance\n",
      "jockey                    523\n",
      "horse_trainer             389\n",
      "horse_owner               367\n",
      "horse_weight              310\n",
      "id                        190\n",
      "race_name                 155\n",
      "day_of_year               150\n",
      "date_sin                  122\n",
      "date_cos                  120\n",
      "race_start                116\n",
      "number_of_entries         115\n",
      "age                       109\n",
      "horse_order               106\n",
      "difference_weight          97\n",
      "burden_weight              86\n",
      "sex_and_age                78\n",
      "box                        53\n",
      "race_distance              35\n",
      "race_place                 31\n",
      "race_weather               10\n",
      "race_course                 9\n",
      "race_state                  8\n",
      "sex                         1\n",
      "fold_2---------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.706438\tvalid_1's auc: 0.682753\n",
      "[20]\ttraining's auc: 0.72555\tvalid_1's auc: 0.692633\n",
      "[30]\ttraining's auc: 0.738611\tvalid_1's auc: 0.696069\n",
      "[40]\ttraining's auc: 0.752412\tvalid_1's auc: 0.700675\n",
      "[50]\ttraining's auc: 0.762803\tvalid_1's auc: 0.70156\n",
      "[60]\ttraining's auc: 0.772084\tvalid_1's auc: 0.703267\n",
      "[70]\ttraining's auc: 0.780911\tvalid_1's auc: 0.703537\n",
      "[80]\ttraining's auc: 0.788982\tvalid_1's auc: 0.703614\n",
      "[90]\ttraining's auc: 0.796748\tvalid_1's auc: 0.703535\n",
      "[100]\ttraining's auc: 0.804123\tvalid_1's auc: 0.702208\n",
      "[110]\ttraining's auc: 0.810454\tvalid_1's auc: 0.701211\n",
      "[120]\ttraining's auc: 0.816187\tvalid_1's auc: 0.701581\n",
      "[130]\ttraining's auc: 0.822243\tvalid_1's auc: 0.701837\n",
      "[140]\ttraining's auc: 0.827604\tvalid_1's auc: 0.700931\n",
      "[150]\ttraining's auc: 0.83296\tvalid_1's auc: 0.699941\n",
      "[160]\ttraining's auc: 0.838387\tvalid_1's auc: 0.700035\n",
      "[170]\ttraining's auc: 0.843366\tvalid_1's auc: 0.700362\n",
      "[180]\ttraining's auc: 0.84846\tvalid_1's auc: 0.699771\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's auc: 0.790469\tvalid_1's auc: 0.703816\n",
      "Test AUC Score: 0.7024511198446873\n",
      "                   importance\n",
      "jockey                    477\n",
      "horse_trainer             291\n",
      "horse_owner               283\n",
      "horse_weight              232\n",
      "id                        143\n",
      "race_name                 131\n",
      "day_of_year               104\n",
      "date_cos                   95\n",
      "age                        94\n",
      "number_of_entries          88\n",
      "difference_weight          84\n",
      "date_sin                   82\n",
      "race_start                 76\n",
      "sex_and_age                74\n",
      "burden_weight              63\n",
      "horse_order                53\n",
      "race_place                 28\n",
      "box                        27\n",
      "race_distance              17\n",
      "race_state                  8\n",
      "race_weather                7\n",
      "race_course                 3\n",
      "sex                         0\n",
      "fold_3---------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.700729\tvalid_1's auc: 0.678964\n",
      "[20]\ttraining's auc: 0.719827\tvalid_1's auc: 0.694037\n",
      "[30]\ttraining's auc: 0.733317\tvalid_1's auc: 0.702462\n",
      "[40]\ttraining's auc: 0.744252\tvalid_1's auc: 0.708044\n",
      "[50]\ttraining's auc: 0.75469\tvalid_1's auc: 0.70961\n",
      "[60]\ttraining's auc: 0.76256\tvalid_1's auc: 0.71003\n",
      "[70]\ttraining's auc: 0.769876\tvalid_1's auc: 0.709128\n",
      "[80]\ttraining's auc: 0.776673\tvalid_1's auc: 0.708798\n",
      "[90]\ttraining's auc: 0.782968\tvalid_1's auc: 0.708898\n",
      "[100]\ttraining's auc: 0.78922\tvalid_1's auc: 0.709114\n",
      "[110]\ttraining's auc: 0.795434\tvalid_1's auc: 0.709452\n",
      "[120]\ttraining's auc: 0.800203\tvalid_1's auc: 0.709177\n",
      "[130]\ttraining's auc: 0.805239\tvalid_1's auc: 0.704883\n",
      "[140]\ttraining's auc: 0.809875\tvalid_1's auc: 0.704935\n",
      "[150]\ttraining's auc: 0.816168\tvalid_1's auc: 0.7059\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.761868\tvalid_1's auc: 0.710285\n",
      "Test AUC Score: 0.7043522962664089\n",
      "                   importance\n",
      "jockey                    418\n",
      "horse_owner               211\n",
      "horse_trainer             206\n",
      "horse_weight              155\n",
      "id                        101\n",
      "age                        97\n",
      "race_name                  88\n",
      "number_of_entries          75\n",
      "day_of_year                65\n",
      "burden_weight              57\n",
      "sex_and_age                50\n",
      "date_cos                   47\n",
      "date_sin                   46\n",
      "difference_weight          42\n",
      "horse_order                35\n",
      "race_start                 32\n",
      "race_place                 16\n",
      "box                         9\n",
      "race_distance               7\n",
      "race_state                  5\n",
      "race_weather                4\n",
      "race_course                 4\n",
      "sex                         0\n",
      "fold_4---------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.700036\tvalid_1's auc: 0.685999\n",
      "[20]\ttraining's auc: 0.714941\tvalid_1's auc: 0.696096\n",
      "[30]\ttraining's auc: 0.728655\tvalid_1's auc: 0.701784\n",
      "[40]\ttraining's auc: 0.739973\tvalid_1's auc: 0.70531\n",
      "[50]\ttraining's auc: 0.748639\tvalid_1's auc: 0.707857\n",
      "[60]\ttraining's auc: 0.756535\tvalid_1's auc: 0.710283\n",
      "[70]\ttraining's auc: 0.763184\tvalid_1's auc: 0.711317\n",
      "[80]\ttraining's auc: 0.769556\tvalid_1's auc: 0.711387\n",
      "[90]\ttraining's auc: 0.775704\tvalid_1's auc: 0.710956\n",
      "[100]\ttraining's auc: 0.781117\tvalid_1's auc: 0.711583\n",
      "[110]\ttraining's auc: 0.786233\tvalid_1's auc: 0.711495\n",
      "[120]\ttraining's auc: 0.791716\tvalid_1's auc: 0.712018\n",
      "[130]\ttraining's auc: 0.795662\tvalid_1's auc: 0.71192\n",
      "[140]\ttraining's auc: 0.800706\tvalid_1's auc: 0.711205\n",
      "[150]\ttraining's auc: 0.805699\tvalid_1's auc: 0.710226\n",
      "[160]\ttraining's auc: 0.809911\tvalid_1's auc: 0.709986\n",
      "[170]\ttraining's auc: 0.814531\tvalid_1's auc: 0.709623\n",
      "[180]\ttraining's auc: 0.818836\tvalid_1's auc: 0.708838\n",
      "[190]\ttraining's auc: 0.823312\tvalid_1's auc: 0.70933\n",
      "[200]\ttraining's auc: 0.827231\tvalid_1's auc: 0.709831\n",
      "[210]\ttraining's auc: 0.831199\tvalid_1's auc: 0.709535\n",
      "[220]\ttraining's auc: 0.834137\tvalid_1's auc: 0.710031\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's auc: 0.793079\tvalid_1's auc: 0.71213\n",
      "Test AUC Score: 0.7093809534536468\n",
      "                   importance\n",
      "jockey                    660\n",
      "horse_trainer             420\n",
      "horse_owner               410\n",
      "horse_weight              356\n",
      "id                        232\n",
      "race_name                 204\n",
      "day_of_year               169\n",
      "date_sin                  150\n",
      "number_of_entries         132\n",
      "age                       130\n",
      "sex_and_age               125\n",
      "difference_weight         119\n",
      "race_start                118\n",
      "date_cos                  115\n",
      "horse_order               109\n",
      "burden_weight              99\n",
      "box                        58\n",
      "race_distance              35\n",
      "race_place                 32\n",
      "race_weather               22\n",
      "race_state                 14\n",
      "race_course                11\n",
      "sex                         0\n"
     ]
    }
   ],
   "source": [
    "train_dates = [dt.datetime(2018, 12, 31), dt.datetime(2019, 12, 31), dt.datetime(2020, 12, 31), dt.datetime(2021, 12, 31), dt.datetime(2022, 12, 31)]\n",
    "val_dates = [dt.datetime(2019, 12, 31), dt.datetime(2020, 12, 31), dt.datetime(2021, 12, 31), dt.datetime(2022, 12, 31), dt.datetime(2023, 12, 31)]\n",
    "test_dates = [dt.datetime(2020, 12, 31), dt.datetime(2021, 12, 31), dt.datetime(2022, 12, 31), dt.datetime(2023, 12, 31), dt.datetime(2024, 12, 31)]\n",
    "\n",
    "def split_df(df, train_date, val_date, test_date):\n",
    "    return_df = df.copy()\n",
    "    train_df = return_df[return_df['date'] < train_date].drop('date', axis=1)\n",
    "    val_df = return_df[(return_df['date'] > train_date) & (return_df['date'] < val_date)].drop('date', axis=1)\n",
    "    test_df = return_df[(return_df['date'] > val_date) & (return_df['date'] < test_date)].drop('date', axis=1)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def split_target(df):\n",
    "    return_df = df.copy()\n",
    "    X = return_df.drop('rank', axis=1)\n",
    "    y = return_df['rank']\n",
    "    return X, y\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"fold_{i}---------------------\")\n",
    "    train_df, val_df, test_df = split_df(preprocessed_df, train_dates[i], val_dates[i], test_dates[i])\n",
    "\n",
    "    X_train, y_train = split_target(train_df)\n",
    "    X_val, y_val = split_target(val_df)\n",
    "    X_test, y_test = split_target(test_df)\n",
    "\n",
    "    train_set = lgbm.Dataset(X_train, y_train)\n",
    "    val_set = lgbm.Dataset(X_val, y_val)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 10000,\n",
    "        'random_state': 74,\n",
    "    }\n",
    "\n",
    "    clf = lgbm.LGBMClassifier(**params)\n",
    "\n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=True), lgbm.log_evaluation(10)])\n",
    "    \n",
    "    evaluation_results = evaluate_model_performance(clf, X_test, y_test, str(i), OUTPUT_PATH)\n",
    "    save_evaluation(evaluation_results, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全てのデータで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, n_estimators=120, objective=&#x27;binary&#x27;,\n",
       "               random_state=74)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, n_estimators=120, objective=&#x27;binary&#x27;,\n",
       "               random_state=74)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='auc', n_estimators=120, objective='binary',\n",
       "               random_state=74)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = split_target(preprocessed_df.drop('date', axis=1))\n",
    "\n",
    "train_set = lgbm.Dataset(X_train, y_train)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 120,\n",
    "    'random_state': 74,\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output\\\\model.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filename = os.path.join(OUTPUT_PATH, \"model.joblib\")\n",
    "dump(clf, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測フロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開催予定レースデータ取得(RDSから)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_data():\n",
    "    query_weekly_races = 'SELECT * FROM weekly_races'\n",
    "    query_race_entries = 'SELECT * FROM race_entries'\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        weekly_races_df = pd.read_sql_query(sql=text(query_weekly_races), con=connection)\n",
    "        race_entries_df = pd.read_sql_query(sql=text(query_race_entries), con=connection)\n",
    "\n",
    "    return weekly_races_df, race_entries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_races_df, race_entries_df = load_new_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineered_df = get_all_features(weekly_races_df, race_entries_df, MODE)\n",
    "preprocessed_df = preprocess_data(feature_engineered_df, MODE, OUTPUT_PATH).drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデル取得(S3から)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(output_path):\n",
    "    model_path = os.path.join(output_path, \"model.joblib\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    model = load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(preprocessed_df)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測結果保存(RDSに)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predict_proba_column(engine, table_name='race_entries', column_name='predict_proba'):\n",
    "    Base.metadata.reflect(engine)\n",
    "    table = Base.metadata.tables[table_name]\n",
    "    \n",
    "    if column_name not in table.c:\n",
    "        with engine.connect() as conn:\n",
    "            sql_statement = text(f'ALTER TABLE {table_name} ADD COLUMN {column_name} FLOAT')\n",
    "            conn.execute(sql_statement)\n",
    "            print(f\"Added '{column_name}' column to '{table_name}' table.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' already exists in '{table_name}' table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(race_entries_df, predictions, table_name='race_entries', column_name='predict_proba'):\n",
    "    add_predict_proba_column(engine, table_name, column_name)\n",
    "\n",
    "    race_entries_df[column_name] = predictions\n",
    "\n",
    "    race_entries_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Saved predictions to '{table_name}' table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'predict_proba' already exists in 'race_entries' table.\n",
      "Saved predictions to 'race_entries' table.\n"
     ]
    }
   ],
   "source": [
    "save_predictions(race_entries_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff69bacaadc7e2cd0d1da4a544b42c7a912005d437346d3412f68a334aa5606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
